{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets as ds\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from rich.progress import track\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c978c3e178a4edb997f990f3b6ce080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/558 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21df4e504caa4df2a1a3774b2fd5b4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/26.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c319a622bd18419bb9a19b3d1a410691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/290595 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = ds.load_dataset(\"Rexhaif/wmt22-23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(dataset):\n",
    "    data = dataset.to_pandas()\n",
    "    result = []\n",
    "    for src, subset in track(data.groupby('src'), description='Processing', show_speed=True):\n",
    "        pairs = list(combinations(subset.to_dict(orient='records'), 2))\n",
    "        for item1, item2 in pairs:\n",
    "            result.append({\n",
    "                'lp': item1['lp'],\n",
    "                'dataset': \"mt-ranking\",\n",
    "                'source': item1['source'],\n",
    "                'src': item1['src'],\n",
    "                'ref': item1['ref'],\n",
    "                'hyp0': item1['hyp'],\n",
    "                'hyp1': item2['hyp'],\n",
    "                'score0': item1['score'],\n",
    "                'score1': item2['score'],\n",
    "                'system0': item1['system'],\n",
    "                'system1': item2['system'],\n",
    "                'score_diff': abs(abs(item1['score']) - abs(item2['score'])),\n",
    "                'score_name': item1['score_name'],\n",
    "                'best_hyp': 0 if item1['score'] > item2['score'] else 1,\n",
    "            })\n",
    "    return pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf095bf433b94535a446b7478ee70390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs_train = make_pairs(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in pairs_train.query(\"source == 'wmt22_mqm' & score_diff > 5 & lp == 'en-ru'\").sort_values('score_diff', ascending=True).head(20).itertuples():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train = pairs_train[pairs_train.lp != 'en-cs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1778511, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train[pairs_train.score_diff > 20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train = ds.Dataset.from_pandas(pairs_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049e1c370d1f43828553595889d5a1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4380653 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs_train = pairs_train.filter(lambda x: x['score_diff'] > 20 if 'mqm' not in x['source'] else x['score_diff'] > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train = pairs_train.remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train = pairs_train.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af29aeebb56940efb20b835d15dd6b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b0f2e225cb4e8b8c980090db3fa986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/640 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01844c6b5ee44b0873eded9ec3eea4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpc/v106be/v106be28/miniforge3/envs/llm-reason/lib/python3.11/site-packages/huggingface_hub/lfs.py:337: UserWarning: hf_transfer is enabled but does not support uploading from bytes or BinaryIO, falling back to regular upload\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f76355a5cb40fa8c68d47922f6d7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/640 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eec4d10b02e495eb22c8dc85ef0d8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e2a11c82c4499388c444c1dd9dade3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/640 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as a binary IO buffer is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4696c14c677a45bd9b44493beb2d8ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Rexhaif/wmt22-23-pairs/commit/0132d6d28fd4f5de6f07497a37c7fdeef5237faa', commit_message='Upload dataset', commit_description='', oid='0132d6d28fd4f5de6f07497a37c7fdeef5237faa', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Rexhaif/wmt22-23-pairs', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Rexhaif/wmt22-23-pairs'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train.push_to_hub('Rexhaif/wmt22-23-pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../training')\n",
    "from metric_utils import DEFAULT_INSTRUCTION, JUDGE_PROMPT_NO_THINKING, JUDGE_PROMPT_THINKING, LANG_CODES, SYSTEM_NO_CHOSEN, SYSTEM_CHOSEN\n",
    "\n",
    "def transform_fn(example, tokenizer=None):\n",
    "        lang1, lang2 = example['lp'].split('-')\n",
    "        source_text = example['src']\n",
    "        instruction = DEFAULT_INSTRUCTION.format(\n",
    "            source_language=LANG_CODES[lang1],\n",
    "            target_language=LANG_CODES[lang2],\n",
    "            source_text=source_text\n",
    "        )\n",
    "\n",
    "        input_message = JUDGE_PROMPT_THINKING.format(\n",
    "            instruction=instruction,\n",
    "            assistant_a_response=example[\"hyp0\"],\n",
    "            assistant_b_response=example[\"hyp1\"]\n",
    "        )\n",
    "\n",
    "        answer = \"A\" if example[\"best_hyp\"] == 0 else \"B\"\n",
    "        answer = f\"{answer}\"\n",
    "\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_NO_CHOSEN},\n",
    "                {\"role\": \"user\", \"content\": input_message},\n",
    "                {\"role\": \"assistant\", \"content\": answer}\n",
    "            ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lp',\n",
       " 'dataset',\n",
       " 'src',\n",
       " 'ref',\n",
       " 'hyp0',\n",
       " 'hyp1',\n",
       " 'score0',\n",
       " 'score1',\n",
       " 'system0',\n",
       " 'system1',\n",
       " 'score_diff',\n",
       " 'score_name',\n",
       " 'best_hyp']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a303fba1f954b69bc1ef4a612ca6cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/270354 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs_train = pairs_train.map(transform_fn, remove_columns=pairs_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are a helpful translation evaluator. You will provide a verdict in a strict format, do not include any other text. Just letter \"A\" or \"B\".',\n",
       "   'role': 'system'},\n",
       "  {'content': \"Please act as an impartial judge and evaluate the quality of the translations provided by two AI assistants in response to the user's request below.\\nSelect the assistant that best adheres to the user's instructions while producing the highest-quality translation overall.\\nBegin by comparing the two translations and reason before you answer.\\nAvoid personal opinions or biases, and do not favor one assistant over the other.\\nYour judgment should be based solely on the quality of the translations and their alignment with the user's instructions.\\nBe objective and impartial. If both translations are equally good, you can choose the one that you prefer.\\n\\nAfter providing your explanation, response strictly in this format: \\n\\n<think>\\n... your reasoning process ...\\n</think>\\n<answer>\\n[A] if Assistant A is better, [B] if Assistant B is better\\n</answer>\\n\\n[User Instruction]\\nTranslate this text from Japanese to English, maintaining the tone, accuracy and ensuring fluency: 特にジャグジーで油断をしていると、 メタボ腹が丸見え状態に。\\n[End of User Instruction]\\n\\n[Start of Assistant A's Response]\\nIf you're in a hot tub, you can see your stomach.\\n[End of Assistant A's Response]\\n\\n[Start of Assistant B's Response]\\nIf you are careless, especially in the Jacuzzi, you will be able to see your metabolic syndrome in full view.\\n[End of Assistant B's Response]\\n\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'B', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e430168ade4d49f788515f9da3222780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3292c9b78af409aaef79004fff76752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/271 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files as bytes or binary IO objects is not supported by Xet Storage. Falling back to HTTP upload.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df80a8b34c6d402c9c6e913e67575dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/354 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Rexhaif/wmt23-pairs-sft/commit/d8e8aa723483ad34e1a7af51fa716287fee9c7de', commit_message='Upload dataset', commit_description='', oid='d8e8aa723483ad34e1a7af51fa716287fee9c7de', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Rexhaif/wmt23-pairs-sft', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Rexhaif/wmt23-pairs-sft'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pairs_train.push_to_hub('Rexhaif/wmt23-pairs-sft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets as ds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-reason",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
